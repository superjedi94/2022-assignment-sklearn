{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dda06341",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import ClassifierMixin\n",
    "\n",
    "from sklearn.model_selection import BaseCrossValidator\n",
    "\n",
    "from sklearn.utils.validation import check_X_y, check_is_fitted\n",
    "from sklearn.utils.validation import check_array\n",
    "from sklearn.utils.multiclass import check_classification_targets\n",
    "from sklearn.metrics.pairwise import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73fddf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.multiclass import unique_labels\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00584b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "\n",
    "from numpy.testing import assert_array_equal\n",
    "\n",
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn_questions import KNearestNeighbors\n",
    "from sklearn_questions import MonthlySplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b796dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNearestNeighbors(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"KNearestNeighbors classifier.\"\"\"\n",
    "\n",
    "    def __init__(self, n_neighbors=1):  # noqa: D107\n",
    "        self.n_neighbors = n_neighbors\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fitting function.\n",
    "\n",
    "         Parameters\n",
    "        ----------\n",
    "        X : ndarray, shape (n_samples, n_features)\n",
    "            Data to train the model.\n",
    "        y : ndarray, shape (n_samples,)\n",
    "            Labels associated with the training data.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        self : instance of KNearestNeighbors\n",
    "            The current instance of the classifier\n",
    "        \"\"\"\n",
    "        self.X_ , self.y_ = check_X_y(X, y)\n",
    "        self.classes_ = unique_labels(self.y_)\n",
    "        check_classification_targets(self.y_)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict function.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray, shape (n_test_samples, n_features)\n",
    "            Data to predict on.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        y : ndarray, shape (n_test_samples,)\n",
    "            Predicted class labels for each test data sample.\n",
    "        \"\"\"\n",
    "        # Check if fit has been called\n",
    "#         check_is_fitted(self)\n",
    "#         # Input validation\n",
    "#         X = check_array(X)\n",
    "#         self.X_ = check_array(self.X_)\n",
    "#         n_test_samples = X.shape[0]\n",
    "#         y_pred = np.zeros(X.shape[0])\n",
    "#         for k in range(n_test_samples):\n",
    "#             dist = np.squeeze(pairwise_distances(self.X_, X[k][np.newaxis]))\n",
    "#             n_closest = np.argpartition(dist, self.n_neighbors)[:self.n_neighbors]\n",
    "#             lst = list(self.y_[n_closest])\n",
    "# #             print(lst)\n",
    "#             y_pred[k] = max(lst,key=lst.count)\n",
    "        X = check_array(X)\n",
    "        check_is_fitted(self)\n",
    "        distance = pairwise_distances(X,self.X_)\n",
    "        n_closest = np.argpartition(distance, self.n_neighbors, axis=1)[:,:self.n_neighbors]\n",
    "        y_pred = stats.mode(self.y_[n_closest], axis=1)[0].ravel()\n",
    "        return y_pred\n",
    "\n",
    "    def score(self, X, y):\n",
    "        \"\"\"Calculate the score of the prediction.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray, shape (n_samples, n_features)\n",
    "            Data to score on.\n",
    "        y : ndarray, shape (n_samples,)\n",
    "            target values.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        score : float\n",
    "            Accuracy of the model computed for the (X, y) pairs.\n",
    "        \"\"\"\n",
    "        sc = 0\n",
    "#         y = check_array(y)\n",
    "        y_pred = self.predict(X)\n",
    "        for i in range(X.shape[0]):\n",
    "            if y_pred[i]==y[i]:\n",
    "                sc+=1\n",
    "        return sc/X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7ac48b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = make_classification(n_samples=200, n_features=20,\n",
    "                           random_state=42)\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, random_state=42)\n",
    "\n",
    "onn = KNearestNeighbors(5)\n",
    "y_pred_me = onn.fit(X_train, y_train).predict(X_test)\n",
    "onn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6469e365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "knn.predict(X_test)\n",
    "knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05801659",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\remih\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\estimator_checks.py:3617: FutureWarning: As of scikit-learn 0.23, estimators should expose a n_features_in_ attribute, unless the 'no_validation' tag is True. This attribute should be equal to the number of features passed to the fit method. An error will be raised from version 1.0 (renaming of 0.25) when calling check_estimator(). See SLEP010: https://scikit-learn-enhancement-proposals.readthedocs.io/en/latest/slep010/proposal.html\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "check_estimator(KNearestNeighbors(n_neighbors=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6f4a85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.core.dtypes.common import is_datetime64_any_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "907f61b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MonthlySplit(BaseCrossValidator):\n",
    "    \"\"\"CrossValidator based on monthly split.\n",
    "\n",
    "    Split data based on the given `time_col` (or default to index). Each split\n",
    "    corresponds to one month of data for the training and the next month of\n",
    "    data for the test.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    time_col : str, defaults to 'index'\n",
    "        Column of the input DataFrame that will be used to split the data. This\n",
    "        column should be of type datetime. If split is called with a DataFrame\n",
    "        for which this column is not a datetime, it will raise a ValueError.\n",
    "        To use the index as column just set `time_col` to `'index'`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, time_col='index'):  # noqa: D107\n",
    "        self.time_col = time_col\n",
    "\n",
    "    def get_n_splits(self, X, y=None, groups=None):\n",
    "        \"\"\"Return the number of splitting iterations in the cross-validator.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Training data, where `n_samples` is the number of samples\n",
    "            and `n_features` is the number of features.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            Always ignored, exists for compatibility.\n",
    "        groups : array-like of shape (n_samples,)\n",
    "            Always ignored, exists for compatibility.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        n_splits : int\n",
    "            The number of splits.\n",
    "        \"\"\"\n",
    "#         X, y = check_X_y(X, y)\n",
    "#         print(X)\n",
    "# #         X = X.reset_index()\n",
    "# #         X = X.set_index('date')\n",
    "#         self.X = X\n",
    "#         print(self.X)\n",
    "#         self.y = y\n",
    "#         self.groups = groups\n",
    "# #         return len(self.X.groupby([self.X.index.month, self.X.index.year]))-1\n",
    "#         return len(self.X.resample('M').max())-1\n",
    "        X = X.reset_index()\n",
    "        datetimes = X[self.time_col]\n",
    "        if not isinstance(X[self.time_col][0], pd.Timestamp):\n",
    "            raise ValueError()\n",
    "        return datetimes.dt.to_period('M').nunique()-1\n",
    "\n",
    "    def split(self, X, y, groups=None):\n",
    "        \"\"\"Generate indices to split data into training and test set.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Training data, where `n_samples` is the number of samples\n",
    "            and `n_features` is the number of features.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            Always ignored, exists for compatibility.\n",
    "        groups : array-like of shape (n_samples,)\n",
    "            Always ignored, exists for compatibility.\n",
    "\n",
    "        Yields\n",
    "        ------\n",
    "        idx_train : ndarray\n",
    "            The training set indices for that split.\n",
    "        idx_test : ndarray\n",
    "            The testing set indices for that split.\n",
    "        \"\"\"\n",
    "\n",
    "        n_samples = X.shape[0]\n",
    "        n_splits = self.get_n_splits(X, y, groups)\n",
    "#         X['month'], X['year'] = X.index.month, X.index.year\n",
    "        X = X.reset_index()\n",
    "#         x2 = X.groupby([X['year'], X['month']], as_index = False).count()\n",
    "#         for i in range(n_splits-1):\n",
    "#             idx_train = X.loc[(X['year']  == x2.iloc[i]['year']) & (X['month']  == x2.iloc[i]['month'])].index\n",
    "#             idx_test = X.loc[(X['year']  == x2.iloc[i+1]['year']) & (X['month']  == x2.iloc[i+1]['month'])].index\n",
    "#             yield (idx_train, idx_test)  \n",
    "        datetimes = X[self.time_col]\n",
    "        year_month = datetimes.dt.to_period('M')\n",
    "        months = np.sort(year_month.unique())\n",
    "        for i in range(n_splits):\n",
    "            idx_train = range(n_samples)\n",
    "            idx_test = range(n_samples)\n",
    "            idx_train = X[year_month == months[i]].index.tolist()\n",
    "            idx_test = X[year_month == months[i + 1]].index.tolist()\n",
    "            yield (\n",
    "                idx_train, idx_test\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "447028f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date = '2021-01-31'\n",
    "shuffle_data = True\n",
    "date = pd.date_range(start='2020-01-01', end=end_date, freq='D')\n",
    "n_samples = len(date)\n",
    "X = pd.DataFrame(range(n_samples), index=date, columns=['val'])\n",
    "y = pd.DataFrame(\n",
    "    np.array([i % 2 for i in range(n_samples)]),\n",
    "    index=date\n",
    ")\n",
    "\n",
    "if shuffle_data:\n",
    "    X, y = shuffle(X, y, random_state=0)\n",
    "\n",
    "X_1d = X['val']\n",
    "cv = MonthlySplit()\n",
    "cv_repr = \"MonthlySplit(time_col='index')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05f4a584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_time_split(end_date, expected_splits, shuffle_data):\n",
    "\n",
    "    date = pd.date_range(start='2020-01-01', end=end_date, freq='D')\n",
    "    n_samples = len(date)\n",
    "    X = pd.DataFrame(range(n_samples), index=date, columns=['val'])\n",
    "    y = pd.DataFrame(\n",
    "        np.array([i % 2 for i in range(n_samples)]),\n",
    "        index=date\n",
    "    )\n",
    "\n",
    "    if shuffle_data:\n",
    "        X, y = shuffle(X, y, random_state=0)\n",
    "\n",
    "    X_1d = X['val']\n",
    "\n",
    "    cv = MonthlySplit()\n",
    "    cv_repr = \"MonthlySplit(time_col='index')\"\n",
    "\n",
    "    # Test if the repr works without any errors\n",
    "    assert cv_repr == repr(cv)\n",
    "\n",
    "    # Test if get_n_splits works correctly\n",
    "    assert cv.get_n_splits(X, y) == expected_splits\n",
    "\n",
    "    # Test if the cross-validator works as expected even if\n",
    "    # the data is 1d\n",
    "    np.testing.assert_equal(\n",
    "        list(cv.split(X, y)), list(cv.split(X_1d, y))\n",
    "    )\n",
    "\n",
    "    # Test that train, test indices returned are integers and\n",
    "    # data is correctly ordered\n",
    "    for train, test in cv.split(X, y):\n",
    "        assert np.asarray(train).dtype.kind == \"i\"\n",
    "        assert np.asarray(test).dtype.kind == \"i\"\n",
    "\n",
    "        X_train, X_test = X.iloc[train], X.iloc[test]\n",
    "        y_train, y_test = y.iloc[train], y.iloc[test]\n",
    "        assert X_train.index.max() < X_test.index.min()\n",
    "        assert y_train.index.max() < y_test.index.min()\n",
    "        assert X.index.equals(y.index)\n",
    "\n",
    "    with pytest.raises(ValueError, match='datetime'):\n",
    "        cv = MonthlySplit(time_col='val')\n",
    "        next(cv.split(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ec48138",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_time_split(end_date, 12, shuffle_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "657c8a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_time_split_on_column(end_date, shuffle_data):\n",
    "\n",
    "    date = pd.date_range(\n",
    "        start='2020-01-01 00:00', end=end_date, freq='D'\n",
    "    )\n",
    "    n_samples = len(date)\n",
    "    X = pd.DataFrame({'val': range(n_samples), 'date': date})\n",
    "    y = pd.DataFrame(\n",
    "        np.array([i % 2 for i in range(n_samples)])\n",
    "    )\n",
    "\n",
    "    if shuffle_data:\n",
    "        X, y = shuffle(X, y, random_state=0)\n",
    "\n",
    "    cv = MonthlySplit(time_col='date')\n",
    "\n",
    "    # Test that train, test indices returned are integers and\n",
    "    # data is correctly ordered\n",
    "    n_splits = 0\n",
    "    last_time = None\n",
    "    for train, test in cv.split(X, y):\n",
    "\n",
    "        X_train, X_test = X.iloc[train], X.iloc[test]\n",
    "        assert X_train['date'].max() < X_test['date'].min()\n",
    "        assert X_train['date'].dt.month.nunique() == 1\n",
    "        assert X_test['date'].dt.month.nunique() == 1\n",
    "        assert X_train['date'].dt.year.nunique() == 1\n",
    "        assert X_test['date'].dt.year.nunique() == 1\n",
    "        if last_time is not None:\n",
    "            assert X_test['date'].min() > last_time\n",
    "        last_time = X_test['date'].max()\n",
    "        n_splits += 1\n",
    "\n",
    "    assert 'idx' not in X.columns\n",
    "\n",
    "    assert n_splits == cv.get_n_splits(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e3a14e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_time_split_on_column(end_date, shuffle_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2102275",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "378dcdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['month'], X['year'] = X.index.month, X.index.year\n",
    "x2 = X.groupby([X['year'], X['month']], as_index = False).count()\n",
    "idx_train_2 = X.loc[(X['year']  == x2.iloc[0]['year']) & (X['month']  == x2.iloc[0]['month'])].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfba53d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
